
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                               %
% Chapter: HourglassCorrection Mon Oct 26 18:56:25 EDT 2015
%                                                               %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Hourglass Correction}
\label{ch:HourglassCorrection}

As discussed in Chapter ~\ref{ch:SystematicCorrections}, the purpose of
determining $\beta^{*}$ and $\theta_{xing}$ is to correct our luminosity
obtained from the Vernier Scan by using a more realistic model of the beams.
The reason this correction bears the name "Hourglass Correction" is historical
and memetic - the beams when focused in to the IR tend to have the geometry of
an hourglass lying on its side, due to the focusing parameter, $\beta^{*}$,
which would be symmetrical about the nominal $z = 0$ point at the center of the
IR, except for that due to the non-zero crossing crossing angle,
$\theta_{xing}$. This is nomrally not visible, when beams are overlapped at $z =
0$, but when beams are displaced, the characteristic shape can be seen by a
splitting of z-vertex profile. The two humps gain unequal heights when the
crossing angle strays away from zero.

Because the shape of this distriubtion depends on the luminosity integral, we
cannot normally fit the z-vertex profile that we obtain from data. However,
using a Toy Monte-Carlo, we an simulate the z-vertex profile, then compare the
simulated profile using least-squares regression and $\chi^{2}$ comparisons. The
simulation depends on about twenty parameters, whose affects I summarize in
table ~\ref{tab:simulationparameters}. 

The luminosity of two beams consisting of colloding bunches of any geometry is
described by the convelution of each bunch density over all four space-time
coordinates:

\begin{equation}
\label{eq:generalluminosity}
\mathcal{L} = {f_{bunch}n_{bunch}\int \int \int \int_{-\infty}^{\infty
}\rho^{+}(x,y,z+ct)\rho^{-}(x,y,z-ct)2c\ dt\ dz\ dx\ dy } 
\end{equation}

\begin{table}
\centering
\begin{tabular}{c p{8cm} p{8cm} }
\toprule
\textbf{Parameter} & \textbf{Description} & \textbf{Distribution Effect}  \\
\midrule 
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
$\sigma_{z}$ & some descriptive text  & more descriptive test  \\
\bottomrule
\end{tabular}
\caption{
Each parameter is initialized directly from data. Parameters which are our goal
to determine, $\beta^{*}$ and $\theta_{xing}$ are obtained from reasonable
ranges predicted by CAD, and then varied until good agreement is reached.
}
\label{tab:simulationparameters}
\end{table}

The toy Monte Carlo is seeded with initial values which are extracted from the
data, and then the parameters are adjusted until suitably matching the data
distribution.


